<div align="center">
  <img src="assets/logo.png" height=100>
  <h1>Step1X-Edit Docker éƒ¨ç½²ç‰ˆ</h1>
  <p>ğŸ¨ æ™ºèƒ½ GPU ç®¡ç†çš„ AI å›¾åƒç¼–è¾‘ç³»ç»Ÿ</p>
  
  [English](README_NEW.md) | [ç®€ä½“ä¸­æ–‡](README_CN.md) | [ç¹é«”ä¸­æ–‡](README_TW.md) | [æ—¥æœ¬èª](README_JP.md)
  
  [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
  [![Docker](https://img.shields.io/badge/Docker-Ready-brightgreen.svg)](Dockerfile)
  [![GPU](https://img.shields.io/badge/GPU-CUDA%2012.1-green.svg)](https://developer.nvidia.com/cuda-toolkit)
  [![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
</div>

## ğŸ“– é¡¹ç›®ç®€ä»‹

Step1X-Edit çš„ç”Ÿäº§çº§ Docker éƒ¨ç½²æ–¹æ¡ˆï¼Œå…·å¤‡æ™ºèƒ½ GPU æ˜¾å­˜ç®¡ç†åŠŸèƒ½ã€‚æ”¯æŒæ‡’åŠ è½½ã€å³ç”¨å³å¸ï¼Œå•å®¹å™¨æä¾›ä¸‰ç§è®¿é—®æ–¹å¼ï¼ˆUI + API + MCPï¼‰ã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸš€ **ä¸€é”®éƒ¨ç½²** - è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ GPU å¹¶å¯åŠ¨
- ğŸ§  **æ™ºèƒ½æ˜¾å­˜ç®¡ç†** - æ‡’åŠ è½½ + å³ç”¨å³å¸ï¼ˆç©ºé—² <1GBï¼‰
- ğŸ¨ **ç°ä»£åŒ– Web UI** - æ‹–æ‹½ä¸Šä¼ ï¼Œå®æ—¶é¢„è§ˆ
- ğŸ”Œ **REST API** - å®Œæ•´ API æ¥å£ï¼ŒSwagger æ–‡æ¡£
- ğŸ¤– **MCP æ”¯æŒ** - æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼Œå¯¹æ¥ AI åŠ©æ‰‹
- ğŸŒ **å¤šè¯­è¨€** - è‹±æ–‡ã€ç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€æ—¥æ–‡
- ğŸ³ **Docker ä¼˜åŒ–** - å•å®¹å™¨ï¼Œæ”¯æŒå¤–éƒ¨è®¿é—®
- ğŸ“Š **GPU ç›‘æ§** - å®æ—¶çŠ¶æ€æ˜¾ç¤ºå’Œæ‰‹åŠ¨æ§åˆ¶

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- NVIDIA GPUï¼ˆ24GB+ æ˜¾å­˜ï¼‰
- NVIDIA é©±åŠ¨ 525+
- Docker 20.10+
- nvidia-docker2

### ä¸‰æ­¥å¯åŠ¨

```bash
# 1. é…ç½®ç¯å¢ƒ
cp .env.example .env
# ç¼–è¾‘ .env ä¸­çš„ MODEL_PATH

# 2. å¯åŠ¨æœåŠ¡ï¼ˆè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ GPUï¼‰
bash start.sh

# 3. è®¿é—®æœåŠ¡
# UI:  http://0.0.0.0:8000
# API: http://0.0.0.0:8000/docs
```

## ğŸ“¦ å®‰è£…éƒ¨ç½²

### æ–¹å¼ä¸€ï¼šDocker éƒ¨ç½²ï¼ˆæ¨èï¼‰

#### å®‰è£… nvidia-docker

```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

#### é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘é…ç½®
nano .env
```

å¿…éœ€é…ç½®ï¼š
```bash
MODEL_PATH=/path/to/Step1X-Edit-model  # æ¨¡å‹è·¯å¾„
PORT=8000                               # æœåŠ¡ç«¯å£
GPU_IDLE_TIMEOUT=60                     # GPU ç©ºé—²è¶…æ—¶ï¼ˆç§’ï¼‰
```

#### å¯åŠ¨æœåŠ¡

```bash
# ä¸€é”®å¯åŠ¨ï¼ˆè‡ªåŠ¨é€‰æ‹© GPUï¼‰
bash start.sh

# æˆ–æ‰‹åŠ¨å¯åŠ¨
docker-compose up -d
```

#### éªŒè¯éƒ¨ç½²

```bash
# è¿è¡Œæµ‹è¯•å¥—ä»¶
bash test_deployment.sh

# æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://0.0.0.0:8000/health

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

### æ–¹å¼äºŒï¼šç›´æ¥è¿è¡Œ

#### å®‰è£…ä¾èµ–

```bash
# å®‰è£… Python åŒ…
pip install -r requirements.txt

# å®‰è£… flash-attention
python scripts/get_flash_attn.py
# æ ¹æ®è¾“å‡ºä¸‹è½½å¹¶å®‰è£…å¯¹åº”çš„ wheel æ–‡ä»¶
```

#### å¯åŠ¨æœåŠ¡å™¨

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export MODEL_PATH=/path/to/model
export PORT=8000
export GPU_IDLE_TIMEOUT=60

# å¯åŠ¨ç»Ÿä¸€æœåŠ¡å™¨
python unified_server.py
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `PORT` | 8000 | æœåŠ¡ç«¯å£ |
| `HOST` | 0.0.0.0 | ç»‘å®šåœ°å€ï¼ˆæ‰€æœ‰ç½‘å¡ï¼‰ |
| `NVIDIA_VISIBLE_DEVICES` | 0 | GPU IDï¼ˆstart.sh è‡ªåŠ¨é€‰æ‹©ï¼‰ |
| `GPU_IDLE_TIMEOUT` | 60 | è‡ªåŠ¨å¸è½½è¶…æ—¶ï¼ˆç§’ï¼‰ |
| `MODEL_PATH` | - | Step1X-Edit æ¨¡å‹è·¯å¾„ï¼ˆå¿…éœ€ï¼‰ |
| `ENABLE_UI` | true | å¯ç”¨ Web UI |
| `ENABLE_API` | true | å¯ç”¨ REST API |
| `ENABLE_MCP` | true | å¯ç”¨ MCP æœåŠ¡å™¨ |
| `DEFAULT_NUM_STEPS` | 28 | é»˜è®¤æ¨ç†æ­¥æ•° |
| `DEFAULT_GUIDANCE_SCALE` | 6.0 | é»˜è®¤ CFG ç³»æ•° |
| `DEFAULT_SIZE_LEVEL` | 1024 | é»˜è®¤åˆ†è¾¨ç‡ |

### Docker Compose é…ç½®

```yaml
version: '3.8'
services:
  step1x-edit:
    build: .
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-0}
      - PORT=${PORT:-8000}
      - GPU_IDLE_TIMEOUT=${GPU_IDLE_TIMEOUT:-60}
      - MODEL_PATH=${MODEL_PATH}
    ports:
      - "${PORT:-8000}:8000"
    volumes:
      - ${MODEL_PATH}:/models
      - ./outputs:/app/outputs
    restart: unless-stopped
```

## ğŸ’» ä½¿ç”¨æ–¹æ³•

### Web UI

1. æ‰“å¼€æµè§ˆå™¨ï¼š`http://0.0.0.0:8000`
2. æ‹–æ‹½å›¾ç‰‡æˆ–ç‚¹å‡»ä¸Šä¼ 
3. è¾“å…¥ç¼–è¾‘æŒ‡ä»¤ï¼ˆå¦‚ï¼š"ç»™äººç‰©æ·»åŠ ä¸€é¡¶çº¢è‰²å¸½å­"ï¼‰
4. è°ƒæ•´å‚æ•°ï¼š
   - **æ­¥æ•°** (10-50)ï¼šè¶Šé«˜è´¨é‡è¶Šå¥½
   - **å¼•å¯¼ç³»æ•°** (1-15)ï¼šè¶Šé«˜æç¤ºè¯å½±å“è¶Šå¼º
   - **åˆ†è¾¨ç‡** (512/768/1024)ï¼šè¾“å‡ºå°ºå¯¸
   - **éšæœºç§å­**ï¼šç”¨äºå¯å¤ç°ç»“æœ
5. ç‚¹å‡»"ç¼–è¾‘å›¾ç‰‡"
6. æŸ¥çœ‹å¯¹æ¯”ç»“æœ

### REST API

#### ç¼–è¾‘å›¾ç‰‡

```bash
curl -X POST http://0.0.0.0:8000/api/edit \
  -F "file=@input.jpg" \
  -F "prompt=ç»™äººç‰©æ·»åŠ ä¸€é¡¶çº¢è‰²å¸½å­" \
  -F "num_steps=28" \
  -F "guidance_scale=6.0" \
  -F "size_level=1024" \
  --output result.png
```

#### æŸ¥è¯¢ GPU çŠ¶æ€

```bash
curl http://0.0.0.0:8000/api/gpu/status
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "model_location": "CPU",
  "idle_time": 45.2,
  "gpu_memory_allocated_gb": 0.12,
  "gpu_memory_reserved_gb": 0.5,
  "statistics": {
    "total_loads": 5,
    "gpu_to_cpu": 5,
    "cpu_to_gpu": 4
  }
}
```

#### æ‰‹åŠ¨ GPU æ§åˆ¶

```bash
# å¸è½½åˆ° CPUï¼ˆä¿ç•™åœ¨å†…å­˜ï¼‰
curl -X POST http://0.0.0.0:8000/api/gpu/offload

# å®Œå…¨é‡Šæ”¾ï¼ˆæ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼‰
curl -X POST http://0.0.0.0:8000/api/gpu/release
```

#### API æ–‡æ¡£

äº¤äº’å¼ Swagger UIï¼š`http://0.0.0.0:8000/docs`

### MCPï¼ˆæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼‰

#### Python å®¢æˆ·ç«¯

```python
from mcp import ClientSession

async with ClientSession() as session:
    result = await session.call_tool(
        "edit_image",
        {
            "image_path": "input.jpg",
            "prompt": "æ·»åŠ çº¢è‰²å¸½å­",
            "num_steps": 28,
            "guidance_scale": 6.0
        }
    )
    print(f"ä¿å­˜è‡³: {result['output_path']}")
```

#### å¯ç”¨å·¥å…·

- `edit_image` - ç¼–è¾‘å•å¼ å›¾ç‰‡
- `batch_edit_images` - æ‰¹é‡ç¼–è¾‘å›¾ç‰‡
- `get_gpu_status` - è·å– GPU çŠ¶æ€
- `offload_gpu` - å¸è½½åˆ° CPU
- `release_gpu` - å®Œå…¨é‡Šæ”¾

è¯¦è§ [MCP_GUIDE.md](MCP_GUIDE.md)

## ğŸ§  GPU æ˜¾å­˜ç®¡ç†

### æ™ºèƒ½èµ„æºç®¡ç†

```
æœªåŠ è½½ â”€â”€é¦–æ¬¡(20-30s)â”€â”€> GPU â”€â”€å®Œæˆ(2s)â”€â”€> CPU â”€â”€ä¸‹æ¬¡(2-5s)â”€â”€> GPU
   â†‘                                          â†“
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€è¶…æ—¶/é‡Šæ”¾(1s)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ˜¾å­˜çŠ¶æ€

| çŠ¶æ€ | GPU æ˜¾å­˜ | è¯´æ˜ |
|------|----------|------|
| æœªåŠ è½½ | <1GB | æ¨¡å‹æœªåŠ è½½ |
| CPU ç¼“å­˜ | <1GB | æ¨¡å‹åœ¨å†…å­˜ï¼Œå¿«é€Ÿé‡è½½ï¼ˆ2-5ç§’ï¼‰ |
| GPU æ´»è·ƒ | ~40GB | æ¨¡å‹åœ¨ GPUï¼Œå¤„ç†ä¸­ |

### åŠŸèƒ½ç‰¹æ€§

- **æ‡’åŠ è½½**ï¼šä»…åœ¨é¦–æ¬¡è¯·æ±‚æ—¶åŠ è½½æ¨¡å‹
- **å³ç”¨å³å¸**ï¼šä»»åŠ¡å®Œæˆåè‡ªåŠ¨è½¬ç§»åˆ° CPUï¼ˆ2ç§’ï¼‰
- **å¿«é€Ÿé‡è½½**ï¼šCPUâ†’GPU ä»…éœ€ 2-5 ç§’
- **è‡ªåŠ¨ç›‘æ§**ï¼šåå°çº¿ç¨‹ï¼Œå¯é…ç½®è¶…æ—¶æ—¶é—´
- **æ‰‹åŠ¨æ§åˆ¶**ï¼šé€šè¿‡ API æˆ– UI å¼ºåˆ¶å¸è½½/é‡Šæ”¾

è¯¦è§ [GPU_MANAGEMENT.md](GPU_MANAGEMENT.md)

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### åŸºå‡†æµ‹è¯•ï¼ˆH800 GPUï¼‰

| æ“ä½œ | è€—æ—¶ | GPU æ˜¾å­˜ |
|------|------|----------|
| é¦–æ¬¡åŠ è½½ï¼ˆç£ç›˜â†’GPUï¼‰ | 20-30ç§’ | ~40GB |
| ç¼–è¾‘ï¼ˆ1024px, 28æ­¥ï¼‰ | 15-20ç§’ | ~40GB |
| é‡è½½ï¼ˆCPUâ†’GPUï¼‰ | 2-5ç§’ | ~40GB |
| å¸è½½ï¼ˆGPUâ†’CPUï¼‰ | ~2ç§’ | <1GB |
| é‡Šæ”¾ï¼ˆæ¸…ç©ºæ‰€æœ‰ï¼‰ | ~1ç§’ | <1GB |

### ä¼˜åŒ–å»ºè®®

- **æ›´å¿«é€Ÿåº¦**ï¼šé™ä½ `num_steps`ï¼ˆ20ï¼‰æˆ– `size_level`ï¼ˆ768ï¼‰
- **æ›´é«˜è´¨é‡**ï¼šæé«˜ `num_steps`ï¼ˆ35-40ï¼‰å’Œ `guidance_scale`ï¼ˆ7-8ï¼‰
- **å¯å¤ç°**ï¼šè®¾ç½® `seed` å‚æ•°
- **é¢‘ç¹ä½¿ç”¨**ï¼šå¢åŠ  `GPU_IDLE_TIMEOUT`

## ğŸ“ é¡¹ç›®ç»“æ„

```
Step1X-Edit/
â”œâ”€â”€ Dockerfile                      # Docker é•œåƒå®šä¹‰
â”œâ”€â”€ docker-compose.yml              # å®¹å™¨ç¼–æ’é…ç½®
â”œâ”€â”€ start.sh                        # ä¸€é”®å¯åŠ¨è„šæœ¬
â”œâ”€â”€ test_deployment.sh              # æµ‹è¯•å¥—ä»¶
â”‚
â”œâ”€â”€ unified_server.py               # UI + API æœåŠ¡å™¨
â”œâ”€â”€ mcp_server.py                   # MCP æœåŠ¡å™¨
â”œâ”€â”€ gpu_manager.py                  # GPU èµ„æºç®¡ç†å™¨
â”œâ”€â”€ step1x_manager.py               # Step1X-Edit å°è£…
â”‚
â”œâ”€â”€ DEPLOYMENT.md                   # éƒ¨ç½²æŒ‡å—
â”œâ”€â”€ GPU_MANAGEMENT.md               # GPU ç®¡ç†æ–‡æ¡£
â”œâ”€â”€ MCP_GUIDE.md                    # MCP ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ QUICK_REFERENCE.md              # å¿«é€Ÿå‚è€ƒ
â”‚
â”œâ”€â”€ modules/                        # æ¨¡å‹æ¨¡å—
â”œâ”€â”€ scripts/                        # å·¥å…·è„šæœ¬
â””â”€â”€ examples/                       # ç¤ºä¾‹å›¾ç‰‡
```

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **æ¡†æ¶**ï¼šFastAPI, Gradio
- **AI/ML**ï¼šPyTorch, Transformers, Diffusers
- **GPU**ï¼šCUDA 12.1, Flash Attention
- **å®¹å™¨**ï¼šDocker, nvidia-docker2
- **åè®®**ï¼šMCPï¼ˆæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼‰
- **API**ï¼šREST, WebSocket, Swagger/OpenAPI

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
bash test_deployment.sh
```

æµ‹è¯•é¡¹ç›®ï¼š
- âœ“ å®¹å™¨å¥åº·æ£€æŸ¥
- âœ“ GPU å¯è®¿é—®æ€§
- âœ“ API ç«¯ç‚¹
- âœ“ UI å¯è®¿é—®æ€§
- âœ“ GPU ç®¡ç†åŠŸèƒ½
- âœ“ å›¾ç‰‡ç¼–è¾‘ï¼ˆå¯é€‰ï¼‰

## ğŸ› æ•…éšœæ’æŸ¥

### å®¹å™¨æ— æ³•å¯åŠ¨

```bash
# æŸ¥çœ‹æ—¥å¿—
docker logs step1x-edit

# æ£€æŸ¥ GPU
nvidia-smi
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

### GPU æ˜¾å­˜å ç”¨é«˜

```bash
# æ£€æŸ¥çŠ¶æ€
curl http://0.0.0.0:8000/api/gpu/status

# æ‰‹åŠ¨å¸è½½
curl -X POST http://0.0.0.0:8000/api/gpu/offload

# éªŒè¯
nvidia-smi
```

### ç«¯å£è¢«å ç”¨

```bash
# ä¿®æ”¹ .env ä¸­çš„ç«¯å£
PORT=8001

# é‡å¯
docker-compose down
bash start.sh
```

å®Œæ•´æ•…éšœæ’æŸ¥æŒ‡å—è§ [DEPLOYMENT.md](DEPLOYMENT.md)

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ï¼ˆ`git checkout -b feature/amazing`ï¼‰
3. æäº¤æ›´æ”¹ï¼ˆ`git commit -m 'æ·»åŠ æŸæŸåŠŸèƒ½'`ï¼‰
4. æ¨é€åˆ°åˆ†æ”¯ï¼ˆ`git push origin feature/amazing`ï¼‰
5. æäº¤ Pull Request

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.2.0 (2025-12-06)
- âœ¨ æ–°å¢ç»Ÿä¸€æœåŠ¡å™¨ï¼ˆUI + API + MCPï¼‰
- ğŸ§  å®ç°æ™ºèƒ½ GPU æ˜¾å­˜ç®¡ç†
- ğŸ³ Docker éƒ¨ç½²ï¼Œè‡ªåŠ¨ GPU é€‰æ‹©
- ğŸ“š å®Œæ•´æ–‡æ¡£
- ğŸ§ª æµ‹è¯•å¥—ä»¶

### v1.1.0 (2025-07-09)
- âœ¨ æ”¯æŒæ–‡ç”Ÿå›¾ï¼ˆT2Iï¼‰
- ğŸ¨ æå‡ç¼–è¾‘è´¨é‡
- ğŸ“Š æ›´å¥½çš„æŒ‡ä»¤éµå¾ª

### v1.0.0 (2025-04-25)
- ğŸ‰ é¦–æ¬¡å‘å¸ƒ
- ğŸ¨ è‡ªç„¶è¯­è¨€å›¾åƒç¼–è¾‘
- ğŸ“Š GEdit-Bench è¯„æµ‹

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apache License 2.0 è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ™ è‡´è°¢

ç‰¹åˆ«æ„Ÿè°¢ï¼š
- [Step1X-Edit å›¢é˜Ÿ](https://github.com/stepfun-ai/Step1X-Edit) - åŸå§‹æ¨¡å‹
- [Kohya](https://github.com/kohya-ss/sd-scripts) - è®­ç»ƒè„šæœ¬
- [xDiT](https://github.com/xdit-project/xDiT) - å¹¶è¡Œæ¨ç†
- [TeaCache](https://github.com/ali-vilab/TeaCache) - åŠ é€Ÿæ–¹æ¡ˆ
- [HuggingFace](https://huggingface.co) - æ¨¡å‹æ‰˜ç®¡

## ğŸ“ è”ç³»ä¸æ”¯æŒ

- **GitHub Issues**ï¼š[æŠ¥å‘Šé—®é¢˜æˆ–åŠŸèƒ½è¯·æ±‚](https://github.com/neosun100/Step1X-Edit/issues)
- **Discord**ï¼š[åŠ å…¥ç¤¾åŒº](https://discord.gg/j3qzuAyn)
- **æ–‡æ¡£**ï¼š[å®Œæ•´æ–‡æ¡£](DEPLOYMENT.md)

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=neosun100/Step1X-Edit&type=Date)](https://star-history.com/#neosun100/Step1X-Edit)

## ğŸ“± å…³æ³¨å…¬ä¼—å·

![å…¬ä¼—å·](https://img.aws.xin/uPic/æ‰«ç _æœç´¢è”åˆä¼ æ’­æ ·å¼-æ ‡å‡†è‰²ç‰ˆ.png)

---

<div align="center">
  ç”± Step1X-Edit ç¤¾åŒºç”¨ â¤ï¸ åˆ¶ä½œ
  <br>
  <sub>å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™å®ƒä¸€ä¸ª â­ï¸</sub>
</div>
